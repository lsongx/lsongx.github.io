<!-- 
    Author: Liangchen Song
    Author URL: https://lsongx.github.io/
    License: Creative Commons Attribution 3.0 Unported
    License URL: http://creativecommons.org/licenses/by/3.0/
-->

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>NeRFPlayer</title>
    <meta name="author" content="Liangchen Song">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Bungee+Shade&family=Titillium+Web&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../style.css">
</head>

<body>
<div class="main" style="max-width: 1080px;">
<div class="content">
<table>
<tbody>
<tr style="text-align:center">
    <td style="font-size: 250%; font-weight: bold; width:1080px"><span class="rainbow">Efficient-NeRF2NeRF</span><br>
    <span style="line-height:100%; font-size: 80%; font-weight: bold"> Streamlining Text-Driven 3D Editing with Multiview
        Correspondence-Enhanced Diffusion Models
</tr>
<tr style="text-align:center">
    <td>
        <p style="font-size: 120%; line-height:100%;">
        <a href="../index.html">Liangchen Song</a><sup style="color: #cb4b16; margin-right:0.4cm;">1</sup> 
        <a href="http://llcao.net/">Liangliang Cao</a><sup style="color: #cb4b16; margin-right:0.4cm;">1</sup>
        <a href="https://jiataogu.me/">Jiatao Gu</a><sup style="color: #cb4b16; margin-right:0.4cm;">1</sup> 
        <a href="https://yifanjiang19.github.io/">Yifan Jiang</a><sup style="color: #cb4b16; ">1</sup><sup style="color: #859900; margin-right:0.4cm;">2</sup>
        <a href="https://cse.buffalo.edu/~jsyuan/">Junsong Yuan</a><sup style="color: #9d00ec; margin-right:0.4cm;">3</sup>
        <a href="https://scholar.google.com/citations?user=xW-IxnwAAAAJ&hl=en">Hao Tang</a><sup style="color: #cb4b16; margin-right:0.4cm;">1</sup> 
        </p>
        <p style="font-size: 90%;"><sup style="margin-left:0cm; color: #cb4b16;">1</sup> Apple
        <sup style="margin-left:0.5cm; color: #859900;">2</sup> UT Austin
        <sup style="margin-left:0.5cm; color: #9d00ec;">3</sup> University at Buffalo</p>
    </td>
</tr>
<tr style="text-align:center">
<td class="btn">
    <a href=""><svg style="width:36px;height:36px;margin-right:8px;margin-bottom:-9px" viewBox="0 0 24 24"><path fill="currentColor" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z"></path></svg>Paper</a>
    <!-- <a style="margin-left: 12pt;" href=""><svg xmlns="http://www.w3.org/2000/svg" style="width:36px;height:36px;margin-right:8px;margin-bottom:-9px" viewBox="0 0 24 24"><path fill="currentColor" d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>Code </a> -->
    <a style="margin-left: 12pt;" href=""><svg xmlns="http://www.w3.org/2000/svg" style="width:36px;height:36px;margin-right:8px;margin-bottom:-9px" viewBox="0 0 24 24"><path fill="currentColor" d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>Code (coming soon)</a>
</td>
</tr>
</tbody>
</table>
</div>

<div class="content">
<h2 style="text-align:center">Video</h2>
<table>
<tbody>
<div class="video-container">
<!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/flVqSLZWBMI" title="Efficient-NeRF2NeRF" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
<iframe width="90%" height="1000" src="https://www.youtube.com/embed/zHSvF50Q6-k" title="Efficient-NeRF2NeRF" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>
</tbody>
</table>
</div>

<div class="content">
<h2 style="text-align:center">Overview</h2>
<table>
<tbody>
<tr>
    <td>The advancement of text-driven 3D content editing has been blessed by the progress from 2D generative diffusion models. However, a major obstacle hindering the widespread adoption of 3D content editing is its time-intensive processing. This challenge arises from the iterative and refining steps required to achieve consistent 3D outputs from 2D image-based generative models. Recent state-of-the-art methods typically require optimization time ranging from tens of minutes to several hours in order to edit a 3D scene using a single GPU. In this work, we propose that by incorporating correspondence regularization into diffusion models, the process of 3D editing can be significantly accelerated. This approach is inspired by the notion that the estimated samples during diffusion should be multiview-consistent during the diffusion generation process. By leveraging these multiview-consistency, we can edit 3D contents with a much faster speed. In most scenarios, our proposed technique brings a 10$\times$ speed-up compared to the baseline method and  completes the editing of a 3D scene in 2 minutes with comparable quality.
    </td>
</tr>
<!-- <tr style="text-align:center">
    <td><img src='images/nerfplayer-framework.png' width="100%"></td>
</tr> -->
</tbody>
</table>
</div>


<div class="content">
<h2 style="text-align:center">Citation</h2>
    <div width='100%' class="cite"> <pre><code>
    </code></pre></div>
</div>


</div>
</body>
<script src="copy.js"></script>
<script src="../script.js"></script>
